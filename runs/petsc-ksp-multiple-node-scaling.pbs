#!/bin/bash -l

#PBS -A gen010interns
#PBS -j oe
#PBS -l walltime=2:00:00
#PBS -l nodes=64
#PBS -l gres=atlas1%atlas2
#PBS -m e
#PBS -M chuangp@ornl.gov

# the name to the project from which CPU hours will be charged
PROJ=gen010

# the name to this run case
RUN=`basename "${PBS_JOBNAME}" ".pbs"`

# the path to the base of this run
RUN_BASE=${PBS_O_WORKDIR}/runs

# the path to the directory where we put results of this run
RUN_PATH=${RUN_BASE}/${RUN}

# the path to the log file
LOG=${RUN_PATH}/${RUN}-${PBS_JOBID}-`date +%Y%m%d-%X`.log

# create the RUN_PATH is it does not exist
if [ ! -d ${RUN_PATH} ]; then mkdir ${RUN_PATH}; fi

# sync the run folder to ${MEMBERWORK}/${PROJ}
rsync -Pravq --delete ${RUN_PATH} ${MEMBERWORK}/${PROJ}

# change the current path to ${MEMBERWORK}/${PROJ}/${RUN}
cd ${MEMBERWORK}/${PROJ}/${RUN}

# sync necessary files here for running on computing nodes
rsync -Pravq ${RUN_BASE}/../bin ${MEMBERWORK}/${PROJ}
rsync -Pravq ${RUN_BASE}/../configs ${MEMBERWORK}/${PROJ}

# environment variable for displaying MPI tasks layout
#export MPICH_RANK_REORDER_DISPLAY=1


# start runs
echo "Multiple-Node Strong Scaling: petsc-ksp" > ${LOG}
echo "=======================================" >> ${LOG}

# print date
date >> ${LOG}
echo "" >> ${LOG}

# loop through and throw all jobs, let system handle resource distribution
for i in 1024 512 256 128 64 32 16
do
    nohup aprun -n ${i} ${MEMBERWORK}/${PROJ}/bin/petsc-ksp \
        -da_grid_x 300 \
        -da_grid_y 300 \
        -da_grid_z 300 \
        -config $MEMBERWORK/${PROJ}/configs/PETSc_SolverOptions_GAMG.info \
        > temp-${i}.log 2>&1 &
done

# wait until all jobs finish
wait

# loop through all job logs and accumulate them
for i in 1024 512 256 128 64 32 16
do
    echo "${i} Cores" >> ${LOG}
    echo "--------" >> ${LOG}
    cat temp-${i}.log >> ${LOG}
    rm temp-${i}.log
    echo "" >> ${LOG}
    echo "" >> ${LOG}
done


# sync the results in ${MEMBERWORK}/${PROJ}/${RUN} to ${RUN_PATH}
rsync -Pravq ${MEMBERWORK}/${PROJ}/${RUN} ${RUN_BASE}
